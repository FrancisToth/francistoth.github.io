[{"content":" Â This is a long due post following the talks given recently at Dawscon, CodeMesh, and Scala Toronto about Functional Design (slides are available here).\n Considering the amount of material available today, Software Design is rather intimidating. When it comes to best practices, one can get overwhelmed quickly and end up with no idea about how to tackle a given problem. Indeed, these guidelines can be vague, or too specific, if not contradictory sometime.\nThe problem is that it\u0026rsquo;s impossible to get all these ideas right without properly understanding their essence. Unfortunately, this is something that tends to be forgotten when teaching design. Too often, we tend to overwhelm people with dozens and dozens of guidelines without actually conveying what ties them all together.\nCoding is like having a civilized and gentle conversation with the future reader of the code. It is about expressing concepts in an intelligible way, to ultimately convince the reader about your solution\u0026rsquo;s correctness. Properly conveying ideas requires these to be organized and structured, so that each of them can be fully understood separately. In some way, this exercise is very similar to what is done when writing a speech or an e-mail.\nThe Path to Abstraction def incByOne(i: Int): Int = ??? scala\u0026gt; val x = incByOne(0) x: Int = 1 scala\u0026gt; val y = incByOne(x) x: Int = 2 As it seems and according its signature, incByOne is a function responsible for incrementing the Int it is provided with incremented by one. This function could be implemented in different ways, using bitwise operators or simply the + function, but that\u0026rsquo;s not really relevant here. In fact, all we care about is that incByOne does what it claims to do.\nIn some cases though, incByOne's implementation may matter. Especially if given a specific argument, it ends up producing an unexpected result:\nscala\u0026gt; incByOne(-1) java.lang.IllegalArgumentException: KABOOM ... 32 elided incByOne(42) This is the meaning of life! res0: Int = 42 This situation has two consequences. First, it\u0026rsquo;s no longer possible to call incByOne and be 100% sure about what it will produce without looking at its internals. In other words, incByOne can no longer be reasoned about without opening it up and guessing what will be produced at runtime. Secondly, refactoring capabilities get lost:\nval a = incByOne(10) // prog1 cannot be used in place of prog2 and vice-versa val prog1 = a val prog2 = incByOne(10) As incByOne(10) may produce an unexpected result, we cannot replace it by a and guarantee that once executed, the program will produce the exact same output than before the refactoring.\nBringing sanity back Let\u0026rsquo;s now compare the two following functions and think about their respective inputs and outputs:\n  Scala 2 Scala 3  def foo(number: Int): Boolean = number == 42 def bar(number: Int): Boolean = { println(\u0026#34;Checking number\u0026#34;) number == 42 }   def foo(number: Int): Boolean = number == 42 def bar(number: Int): Boolean = println(\u0026#34;Checking number\u0026#34;) number == 42    According their signature foo and bar both take an Int and produce a Boolean. However, calling bar results also in printing out \u0026quot;Checking number\u0026quot; on the console. Note that this extra output is not captured anywhere in bar's signature.\nThis second output is called a side-effect. In practice, a side-effect is created whenever a function:\n requires some input which is not part of its argument list, and/or produces an output which is not captured by its result type.  In other words, a side-effect is produced when a function interacts with its environment other that through its arguments or its returned type. As explained earlier, this has important consequences in terms of refactoring capabilities but not only. Compared to bar and incByOne, functions such as foo have a very interesting property called Local Reasoning.\n Local Reasoning enables a reader to make sense of a function without looking at how it\u0026rsquo;s implemented.\n This is a key principle in Software Design and is what enables a component to be abstracted over without knowing about its internals. A good analogy for this is language. In common language, we do not need to explain how a car works every time one needs to be mentioned. The word car can actually be used to define/compose more sophisticated concepts (such as a sports car) and express ourselves in a more concise and meaningful way.\nBack to Software Design, it is common to see codebases having reached a level of complexity preventing their maintainers to do any change without risking major breakdowns. The problem is that beyond a certain point, it is impossible to picture how a program behaves at runtime and be 100% confident about its output without relying on proper abstractions. In other words, if we cannot reason about a word/function\u0026rsquo;s definition, there is no way we can abstract over it to express a higher level concept.\nBack to real world Local Reasoning is a critical concept but there is one issue though. It prevents using exceptions, null values, and any statement in general (println, readLine\u0026hellip;) as these all result in some side-effect or output that cannot be captured by a function\u0026rsquo;s signature.\nHowever, side-effects are a necessary evil. Indeed, these are always needed whether to get some data from the user, load a configuration, access a database or else. So Local Reasoning is pretty cool on paper, but when it comes to real-world use cases, finding a middle ground is required:\n  Scala 2 Scala 3  import scala.io.StdIn.readLine def welcome(): Unit = { val name = readLine() println(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) }   import scala.io.StdIn.readLine def welcome(): Unit = val name = readLine() println(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;)    As you probably guess, this program contains two side-effects:\n readLine() which performs a read from the console println() which outputs a string on it  Unfortunately, the inputs and the outputs of these functions cannot be captured in any way. This is due to the nature of readLine() and println() which are statements. Statements are units of execution being run for their side-effects only. For this reason, they are eager, non-deterministic (as anything could happen at runtime), and cannot be replaced by the value they produce. There\u0026rsquo;s not much we can do about this, but there should be a way to delay their execution, and represent them so that they are locally reasonable.\nClassical approach Usually, this kind of problem is solved by introducing a dependency:   Scala 2 Scala 3  trait Console { def putStrLn(s: String): Unit def getStrLn(): String } def program(console: Console): Unit = { val name = console.getStrLn() console.putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) }   trait Console: def putStrLn(s: String): Unit def getStrLn(): String def program(console: Console): Unit = val name = console.getStrLn() console.putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;)    This approach makes program a bit safer to use because we have now control over how side-effects are performed, but calling putStrLn or getStrLn() may still result in a side-effect, preventing them to be reasoned about locally. Another downside is that this approach is a poor way to manage dependencies in general as these have to be provided up-front. Applied to a more complex program, this strategy may result indeed in a lack of flexibility and in providing an ever growing context any time we need to use program:\n  Scala 2 Scala 3  def complexProgram(module1: Module1, ..., mn: ModuleN): Unit = { val a = foo(module1, ..., mn) val b = bar(module2, ..., mn) fooBar(a, b, module1, module2 ..., mn) }   def complexProgram(module1: Module1, ..., mn: ModuleN): Unit = val a = foo(module1, ..., mn) val b = bar(module2, ..., mn) fooBar(a, b, module1, module2 ..., mn)    From Statements to Values Another approach is to bring these statements back to the world of values:   Scala 2 Scala 3  import scala.io.StdIn.readLine class IO[A](val run: () =\u0026gt; A) object IO { def apply[A](run: =\u0026gt; A): IO[A] = new IO(() =\u0026gt; run) def putStrLn(s: String): IO[Unit] = IO(println(s)) def getStrLn : IO[String] = IO(readLine()) }   import scala.io.StdIn.readLine class IO[A](val run: () =\u0026gt; A) object IO: def apply[A](run: =\u0026gt; A): IO[A] = new IO(() =\u0026gt; run) def putStrLn(s: String): IO[Unit] = IO(println(s)) def getStrLn : IO[String] = IO(readLine())    IO models a lazy instruction (run) which once executed produces an A. This enables the conversion of statements such as println into values, and to delay the resulting side-effects produced during execution. In order to model the previous program, we would however need a way to sequence two IO which can be done using the andThen operator:\n  Scala 2 Scala 3  class IO[A](val run: () =\u0026gt; A) { def andThen[B](f: A =\u0026gt; IO[B]): IO[B] = IO(f(run()).run()) } // ... import IO._ // description of the program (\u0026#39;the what\u0026#39;) val welcome: IO[Unit] = getStrLn.andThen(name =\u0026gt; putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) )   class IO[A](val run: () =\u0026gt; A): def andThen[B](f: A =\u0026gt; IO[B]): IO[B] = IO(f(run()).run()) // ... import IO._ // description of the program (\u0026#39;the what\u0026#39;) val welcome: IO[Unit] = getStrLn.andThen(name =\u0026gt; putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) )    andThen pipes the result of an IO to a function producing another IO (you may know this combinator as flatMap). Using andThen, we can now express the previous program and substitute welcome by its definition without affecting the program\u0026rsquo;s final output:\n// prog1 and prog2 are indeed equivalent val prog1 = welcome val prog2 = getStrLn.andThen(name =\u0026gt; putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) But welcome is just a value, and cannot do much on its own. It\u0026rsquo;s a simple data-structure describing what we\u0026rsquo;d like to do. To materialize this description, we have to call run:\n// execution of the program (the \u0026#39;how\u0026#39;) welcome.run() Whenever run is called, the program performs any side-effect required to produce the final value. This encoding leads to a complete separation of a program\u0026rsquo;s description (the what) and its execution (the how). As long as run() is not called, we keep the guarantees provided by local reasoning along with its super-powers, and have control over WHEN side-effects are performed.\nThis tells us something about when and where side-effects should be executed. As nothing can be guaranteed beyond the execution of a side-effect, we should design the program so that it\u0026rsquo;s always the last thing we do. Once we get to that point, we lose Local Reasoning and have reached the edges of the program.\nHexagonal Architecture Let\u0026rsquo;s take a quick detour and talk about what we mean by edges. As we\u0026rsquo;ve seen it earlier Local Reasoning gets compromised whenever side-effects come into play. In order to keep the code locally reasonable, we therefore delay the moment when side effects are executed until they are absolutely needed. This practice has actually been \u0026ldquo;preached\u0026rdquo; since a long time ago. In general, a business application can be divided in two main sections:\n The business logic or the core, which is prone to change a lot and the infrastructures relying on it, which are pretty static    The infrastructures (such as a testing, a file or a database layer) all depend on the core and reside therefore at the edges of the program\u0026rsquo;s architecture, while the core is completely agnostic about how it is used (by leveraging inversion of control). This approach has different names (Hexagonal architecture, Onion architecture, Ports and Adapters) but overall the goal is always the same: Keep what changes the most (the core) independent of what uses it (the infrastructures).\nAs it is more common to modify the business logic of an application than its infrastructures, it is paramount to prevent the core from being polluted with any aspects related to its context of usage or execution. This guarantees that the same business logic can be re-used in multiple contexts (eg: unit testing, integration testing, production, \u0026hellip;) without modifying it.\nRevisiting IO Let\u0026rsquo;s look back at our example. welcome is locally reasonable, but it has a direct dependency on its execution details (represented by run). Ideally, we\u0026rsquo;d like to invert this dependency so that the business logic described by welcome can be re-used to create programs interacting with different environment such as a console, a web server, or anything else.\nSecondly this approach shows some limits in the testing phase:\n// Using scala-test \u0026#34;StrLn\u0026#34; should \u0026#34;read an input from the console\u0026#34; in { val actual: IO[String] = ??? actual.run() should be getStrLn.run() // ??? } With the current implementation, two IO cannot be compared without executing their respective side-effects, which brings us back to square one. Let\u0026rsquo;s see if we can solve this problem using a different encoding:   Scala 2 Scala 3  sealed trait IO[A] { self =\u0026gt; def andThen[B](f: A =\u0026gt; IO[B]): IO[B] = IO.AndThen(self, f) } object IO { case class PutStrLn(s: String) extends IO[Unit] case object GetStrLn extends IO[String] case class AndThen[A, B]( io: IO[A], f: A =\u0026gt; IO[B] ) extends IO[B] def putStrLn(s: String): IO[Unit] = PutStrLn(s) def getStrLn : IO[String] = GetStrLn } // ... val welcome: IO[Unit] = getStrLn.andThen(name =\u0026gt; putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) ) // AndThen(GetStrLn, name =\u0026gt; PutStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;))   enum IO[A]: self =\u0026gt; def andThen[B](f: A =\u0026gt; IO[B]): IO[B] = AndThen(self, f) case PutStrLn(s: String) extends IO[Unit] case GetStrLn extends IO[String] case AndThen[A, B](io: IO[A], f: A =\u0026gt; IO[B]) extends IO[B] object IO: def putStrLn(s: String): IO[Unit] = PutStrLn(s) def getStrLn : IO[String] = GetStrLn // ... val welcome: IO[Unit] = getStrLn.andThen(name =\u0026gt; putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) ) // AndThen(GetStrLn, name =\u0026gt; PutStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;))   \nIn this encoding, each instruction of our API is represented by a pure data-structure. The definition of welcome stays the same, but this time it is represented by a recursive tree structure which can be inspected, traversed and even optimized if needed. Secondly, instead of embedding the evaluation function run into IO, we define it aside:\n  Scala 2 Scala 3  def run[A](program: IO[A]): A = program match { case GetStrLn =\u0026gt; scala.io.StdIn.readLine() case PutStrLn(s) =\u0026gt; println(s) case AndThen(c, f) =\u0026gt; // not stack safe!!  val io = f(run(c)) run(io) }   def run[A](program: IO[A]): A = program match case GetStrLn =\u0026gt; scala.io.StdIn.readLine() case PutStrLn(s) =\u0026gt; println(s) case AndThen(c, f) =\u0026gt; // not stack safe!!  val io = f(run(c)) run(io)    From a testing perspective, this approach provides a solution to the problem described earlier. Indeed, all we require now is an additional test-specific evaluation function:\n  Scala 2 Scala 3  // program\u0026#39;state case class State(inputs: List[String], outputs: List[String] = List.empty) { def popInput(default: String): (State, String) = (copy(inputs = inputs.tail), inputs.headOption.getOrElse(default)) def pushOutput(s: String): (State, Unit) = (copy(outputs = outputs :+ s), ()) } // test-specific evaluation function / interpreter def testRun[A](program: IO[A], state: State): (State, A) = program match { case GetStrLn =\u0026gt; state.popInput(\u0026#34;Inputs exhausted!\u0026#34;) case PutStrLn(s) =\u0026gt; state.pushOutput(s) case AndThen(io, f) =\u0026gt; // not stack safe!!  val (state0, a) = testRun(io, state) testRun(f(a), state0) }   // program\u0026#39;state case class State(inputs: List[String], outputs: List[String] = List.empty): def popInput(default: String): (State, String) = (copy(inputs = inputs.tail), inputs.headOption.getOrElse(default)) def pushOutput(s: String): (State, Unit) = (copy(outputs = outputs :+ s), ()) // test-specific evaluation function / interpreter def testRun[A](program: IO[A], state: State): (State, A) = program match case GetStrLn =\u0026gt; state.popInput(\u0026#34;Inputs exhausted!\u0026#34;) case PutStrLn(s) =\u0026gt; state.pushOutput(s) case AndThen(io, f) =\u0026gt; // not stack safe!!  val (state0, a) = testRun(io, state) testRun(f(a), state0)    run and testRun go through each layer of the program provided and perform any side-effect required to produce the final value. Note these implementations are not stack-safe and would blow up with infinite recursive programs. This can be fixed using Trampolining but that will be the topic of another blog post. In any case, thanks to this approach, comparing two IO is now trivial:\nval actual = testRun(welcome, State(List(\u0026#34;Bob\u0026#34;))) actual shouldBe (State(List.empty, List(\u0026#34;Hi Bob!\u0026#34;)), ()) Let\u0026rsquo;s take some steps back and look at where interpreters fit in the Hexagonal Architecture. Each interpreter is specific to the layer / context where it is used, maintains a direct dependency towards the core, and therefore resides at the edges of the architecture like shown on this diagram:\n  Note that this approach also opens the door for optimization. We could for example write an interpreter which only purpose is to translate some business logic to an optimized evaluation function that maximizes performances at runtime, or one that optimizes the resulting data-structure into something more manageable. The Sky is the limit.\nComposition Despite being different, these two encodings happen to have many similarities. Indeed, both approaches model the domain in terms of primitives, constructors and operators. This is something we\u0026rsquo;ve already covered in a previous post, but it would be awkward not to mention this here. In any case, these building blocks are what enables us to introduce the third principle of Functional Design which is Composition.\nIf we think about it, designing software goes back to create small simple blocks and to combine these using operators to build bigger blocks. This is the essence of Composition. However, this cannot be achieved if we cannot abstract over these blocks. Hence why Local Reasoning and Purity are so critical.\nLocal Reasoning, Purity and Composition are therefore the three fundamentals we should look for when writing Software, as these pillars will allow an API to be decomposed and recomposed in order to support new business requirements or allow us/you/one to modify \u0026amp; simplify existing business requirements whilst minimizing complexity.\nTo infinity and beyond The example we took is rather simple. Let\u0026rsquo;s add some spice and think about how error recovery could be implemented. In order to achieve this, we would need two additional primitives:\n  Scala 2 Scala 3  sealed trait IO[+A] { self =\u0026gt; // ...  def fail(th: Throwable): IO[A] = IO.fail(th) def retry(n: Int): IO[A] = IO.Retry(self, n) } object IO { case class Fail(th: Throwable) extends IO[Nothing] case class Retry[A](io: IO[A], n: Int) extends IO[A] // ...  def fail[A](th: Throwable) : IO[A] = Fail(th) def retry[A](io: IO[A], n: Int): IO[A] = Retry(io, n) } def run[A](io: IO[A]): Try[A] = io match { // ...  case Fail(th) =\u0026gt; Failure(th) case Retry(io, n) =\u0026gt; run(io) match { case Success(a) =\u0026gt; Success(a) case Failure(th) if n \u0026lt;= 1 =\u0026gt; run(fail(th)) case Failure(th) =\u0026gt; run(Retry(io, n - 1)) } }   enum IO[+A]: self =\u0026gt; // ...  case Fail(th: Throwable) extends IO[Nothing] case Retry(io: IO[A], n: Int) extends IO[A] object IO: def fail[A](th: Throwable): IO[A] = Fail(th) def retry[A](io: IO[A], n: Int): IO[A] = Retry(io, n) import scala.util.{Try, Success, Failure} import IO._ def run[A](io: IO[A]): Try[A] = io match // ...  case Fail(th) =\u0026gt; Failure(th) case Retry(io, n) =\u0026gt; run(io) match case Success(a) =\u0026gt; Success(a) case Failure(th) if n \u0026lt;= 1 =\u0026gt; run(fail(th)) case Failure(th) =\u0026gt; run(Retry(io, n - 1))    With these new building blocks in our tool belt, we can now express more sophisticated program such as this one:\nval welcome: IO[Unit] = getStrLn.andThen(login =\u0026gt; if(login != \u0026#34;admin\u0026#34;) fail(new InvalidLoginException()) else putStrLn(\u0026#34;Hi \u0026#34; + name + \u0026#34;!\u0026#34;) )  Note the type of run. It returns a Try[A] which captures all the outputs run can produce. Try[A] is referred to as an effect, which in contrast with a side-effect is expected by the caller of run. In other words, the difference between an effect and a side-effect is their expected nature.\n Now let\u0026rsquo;s think about how would we describe the same program using a more classical or imperative approach. We would probably need a for-loop, a try-catch, a bunch of if-blocks, and end up with a program that is 20 lines long with no way to reuse the logic we\u0026rsquo;ve just created. Functional Design enables us to do exactly that and to express more powerful constructs with minimal changes.\nCosts You may wonder about the complexity of the encoding. Keep in mind that in real-world scenarios, instead of re-inventing the wheel, one would rely on existing libraries such as ZIO and Cats Effect. These would provide you with all the basic machinery rto express the business logic along with providing you optimized interpreters and concurrency constructs as well.\nSecondly, another common question is the number of allocations required by the description of a program. Indeed, this requires some allocations in order to be created, but this is irrelevant as the cost of instantiating a data-structure is negligible compared to how it is used at runtime. In other words, the performance of a program encoded like above mostly depend on how it is executed. The more optimized the interpreter, the more efficient is the program. From that perspective, libraries such as the ones mentioned earlier are usually comparable to existing solutions available today if not more efficient (Although it always depends on the use-case).\nWrap-Up As we\u0026rsquo;ve seen it, Local Reasoning is critical to leverage abstraction in a codebase. However it prevents a program from doing anything meaningful such as writing in a file or getting some data from the console, as these lead to perform side-effects. This can be mitigated by delaying the execution of side-effects until these are absolutely needed using a declarative or executable encoding. Finally we talked about Composition which ensures a model can always be composed and recomposed to introduce new business requirements easily or modify existing ones.\nIt\u0026rsquo;s important to mention that overall this is not really about the paradigm used to design a program but more about these three fundamentals. Having said that, Functional Programming leads you naturally to adopt them through Referential Transparency and Lazy Evaluation among others. Unfortunately, Functional Programming is usually taught mostly using concepts that may be intimidating, but this does not have to be done like this. By keeping this small subset of concepts in mind, you can quickly ramp up and be productive.\nWhere to go next? The Functional Programming course provided by John DeGoes on Patreon is a good place to start, and is where I\u0026rsquo;ve learnt a lot regarding the concepts described in this post.\nSecondly, there is the Zionomicon which is ZIO\u0026rsquo;s bible, and Essential Effect by Adam Rosien, which is more focused on Cats Effect. The combination of these two can give you a good picture of how Functional Programming is today done in Scala. I would also recommend Functional Programming with Scala aka the \u0026ldquo;Red book\u0026rdquo; which is good but a bit rough for new comers (Please note that there has been a lot of innovation in this space so you might be looking at outdated content especially when it comes to certain later chapters).\nFinally, F# for fun and profit is also a good resource. It\u0026rsquo;s not Scala but the concepts described are relevant to most of languages, and Scott Wlaschin (its author) is an incredible teacher, who worked among others on integrating DDD using a Functional approach.\nThanks I\u0026rsquo;d like to thank John De Goes, Calvin Lee Fernandes along with the Spartan community for their support, help and friendship, and of course, you for reading :)\n","permalink":"https://contramap.dev/posts/2021-01-22-functional_design/","summary":"This is a long due post following the talks given recently at Dawscon, CodeMesh, and Scala Toronto about Functional Design (slides are available here).\n Considering the amount of material available today, Software Design is rather intimidating. When it comes to best practices, one can get overwhelmed quickly and end up with no idea about how to tackle a given problem. Indeed, these guidelines can be vague, or too specific, if not contradictory sometime.","title":"Functional Design"},{"content":"An efficient software design is one allowing its components to be separated and recombined without introducing unexpected behaviors. This topic has been tackled over and over in the past and different approaches like the SOLID principles or the GOF patterns eventually came up to address this problem. Despite their value, these tend to confuse many software developers however. Taken separately, they may indeed sound incomplete and often fail to convey what ties them all together.\nIf we look at this from a higher perspective, they all share the same goal: Making it easier to introduce new business requirements and modify existing ones, while preserving certain properties. In other words: Composition. In this post, we\u0026rsquo;ll look at some simple composition techniques along with some of the perspectives they offer in terms of design.\nPapers, please  Papers, please is a game created by Lucas Pope in which the player takes on the role of a border-crossing immigration officer in a fictional dystopian country. The game takes place at a migration checkpoint. As the immigration officer, the player must review each immigrant and return citizen\u0026rsquo;s passports and other supporting paperwork against an ever-growing list of rules using a number of tools and guides, allowing in only those with the proper paperwork while rejecting those without all proper forms, and at times detaining those with falsified information, while also balancing personal finances.\n In the next sections, we\u0026rsquo;ll model a simplified version of this game to illustrate different patterns you may come across while writing software.\nThe domain Papers, please\u0026rsquo;s domain is pretty simple in essence and can be thought about like a business rule engine where each rule defines whether a person can be let through the border or not. First, we need to model the different documents that could be required by the immigration office:\ntype Date = Long type UID = String /* (firstName, lastName, Date Of Birth) */ type Id = (String, String, Date) sealed trait Document object Document { /* * Required by any person attempting to cross the border except * in the case of a asylum request. */ final case class Passport( uid: UID, // A unique id tying a person\u0026#39;s papers  id: Id, // The owner\u0026#39;s identity  expiration: Date, // the passport\u0026#39;s expiration date  foreign: Boolean // tells if the passport is foreign or not  ) extends Document /* Required by all foreigners */ final case class EntryPermit(uid: UID, id: Id, expiration: Date) extends Document /* Required by citizens getting back in the country */ final case class IdCard(uid: UID, id: Id) extends Document /* Required by asylum seekers */ final case class FingerPrints(data: String) extends Document /* Required by asylum seekers */ final case class GrantOfAsylum( uid: UID, id: Id, fingerPrints: FingerPrints ) extends Document } A Rule defines in what circumstances a person is allowed to cross the border. It\u0026rsquo;s essentially a function taking some input and returning a Result.\ncase class Rule[A](run: A =\u0026gt; Result) A Result states whether a person can cross the border or not (Approved or Denied). If it comes out that some papers have been forged, their owner ends up in custody (Detained). Finally, the game defines that the checking process can be aborted in case of extreme circumstances like a terrorist attack (Aborted).\nsealed trait Result object Result { case object Approved extends Result // Visitor can be let through  case object Denied extends Result // Requirements are not met  case object Detained extends Result // Papers are forged  case object Aborted extends Result // In case of a terrorist attack } The rules Having this in mind, let\u0026rsquo;s try to model some rules:\nobject Rule { /* Creates a `Rule` from a boolean function */ def isTrue[A](f: A =\u0026gt; Boolean): Rule[A] = Rule(a =\u0026gt; if (f(a)) Approved else Denied) /* Succeeds if the passport is not expired */ val notExpired: Rule[(Date, Date)] = isTrue { case (left, right) =\u0026gt; left \u0026lt;= right } /* Succeeds if the passport belongs to a citizen */ val citizenPassport: Rule[Passport] = isTrue(p =\u0026gt; !p.foreign) /* Succeeds if the passport belongs to a foreigner */ val foreignPassport: Rule[Passport] = isTrue(_.foreign) /* Succeeds if the passport matches the id card */ val passportMatchesIdCard: Rule[(Passport, IdCard)] = isTrue { case (passport, idCard) =\u0026gt; passport.id == idCard.id \u0026amp;\u0026amp; passport.uid == idCard.uid } /* Succeeds if the passport matches the entry permit */ val passportMatchesEntryPermit: Rule[(Passport, EntryPermit)] = isTrue { case (passport, permit) =\u0026gt; passport.uid == permit.uid \u0026amp;\u0026amp; passport.id == permit.id } } In Papers, please, the border can only be crossed if the visitor provides:\n a non-expired citizen passport and a matching id card a non-expired foreign passport and a matching entry permit a grant of asylum and matching fingerprints In any other case, the visitor either provided the wrong documents or attempted to cross the border with forged papers.  The above rules provide solutions for the most basic cases, but cannot cover more complex ones like we just described.\nComposing rules Ideally we\u0026rsquo;d like to avoid duplication and make these rules composable. Let\u0026rsquo;s try to model the citizen rule which requires a non-expired citizen passport along with a matching id-card:\nobject Rule { // ...  val citizen: Rule[(Date, Passport, IdCard)] = Rule { case (now, passport, id) =\u0026gt; val result0 = citizenPassport.run(passport) val result1 = notExpired.run((passport.expiration, now)) val result2 = passportMatchesIdCard.run((passport, id)) // No way to combine results so far  ??? } } We currently have no way to combine results, and therefore need to add some machinery to achieve that. Let\u0026rsquo;s add an operator \u0026amp;\u0026amp; to Result:\nsealed trait Result { self =\u0026gt; def \u0026amp;\u0026amp;(that: Result): Result = (self, that) match { case (_, Aborted) =\u0026gt; that // process has been aborted  case (Approved, _) =\u0026gt; that // left side is ok, keep proceeding  case _ =\u0026gt; self // left side is not ok, do not proceed  } } The citizen rule can be now built like this:\nobject Rule { // ...  val citizen: Rule[(Date, Passport, IdCard)] = Rule { ctx =\u0026gt; case (now, passport, id) =\u0026gt; val result0 = citizenPassport.run(passport) val result1 = notExpired.run((passport.expiration, now)) val result2 = passportMatchesIdCard.run((passport, id)) result0 \u0026amp;\u0026amp; result1 \u0026amp;\u0026amp; result2 } } This leads us to a first best practice to make a DSL composable: provide binary operators returning their inputs type:\n(A, A) =\u0026gt; A This is exactly what we\u0026rsquo;ve done with Result.\u0026amp;\u0026amp; which takes two Result's (self and that) and returns another Result combining them. This operator helped us implementing the citizen but we can do better. To simplify the addition of other rules, we should also provide a combinator to Rule so that:\n// Pseudo code: val citizen = citizenPassport \u0026amp;\u0026amp; passportNotExpired \u0026amp;\u0026amp; passportMatchesIdCard Let\u0026rsquo;s build this step by step. First we need to add the operator in question:\ncase class Rule[A](run: A =\u0026gt; Result) { self =\u0026gt; /* * Combines two rules and returns another one requiring a product * of their input */ def \u0026amp;\u0026amp;[B](that: Rule[B]): Rule[(A, B)] = Rule { case (a, b) =\u0026gt; self.run(a) \u0026amp;\u0026amp; that.run(b) } } The citizen rule can now be formed like following:\nval citizen: Rule[((Passport, (Date, Date)), (Passport, IdCard))] = citizenPassport \u0026amp;\u0026amp; notExpired \u0026amp;\u0026amp; passportMatchesIdCard citizen's type is awkward however and contains many redundancies. Ideally, we\u0026rsquo;d like something closer to:\nval citizen: Rule[(Passport, Date, IdCard)] = ??? In order to run this rule, we would have to provide a tuple containing the passport, the current date, and a matching id card. These inputs could be then redistributed to the different underlying rules forming the resulting composition. This operator would therefore look like this:\ndef bothWith[B, C](that: Rule[B])(f: C =\u0026gt; (A, B)): Rule[C] = ??? In other words, as long as we know how to decompose an input C into a product of A and B, we can combine two rules taking respectively an A and a B. The implementation happens to be quite straightforward:\ncase class Rule[-A](run: A =\u0026gt; Result) { self =\u0026gt; // ...  /* * Combines two rules respectively requiring an `A` and a `B` * into a rule requiring a `(A, B)`. */ def bothWith[B, C]( that: Rule[B] )(f: C =\u0026gt; (A, B)): Rule[C] = Rule { c =\u0026gt; val (a, b) = f(c) self.run(a) \u0026amp;\u0026amp; that.run(b) } } As a matter of fact, \u0026amp;\u0026amp; can be expressed in terms of bothWith making it a derived operator:\ncase class Rule[A](run: A =\u0026gt; Result) { self =\u0026gt; /* * Alias for `both` */ def \u0026amp;\u0026amp;[B](that: Rule[B]): Rule[(A, B)] = both(that) /* Alias for `bothWith` provided with the `identity` function */ def both[B](that: Rule[B]): Rule[(A, B)] = bothWith(that)(identity) /* * Combines two rules respectively requiring an `A` and a `B` * into a rule requiring a product of A and B. */ def bothWith[B, C]( that: Rule[B] )(f: C =\u0026gt; (A, B)): Rule[C] = Rule { c =\u0026gt; // As long as we know how to extract `A` et `B` from `C`,  // we can build a `Rule[C]` from a `Rule[A]` and a `Rule[B]`  val (a, b) = f(c) self.run(a) \u0026amp;\u0026amp; that.run(b) } } bothWith is one of the typical composition patterns you may come across while writing composable software. It fits well with data-structures being invariant or contravariant in A, that is which provide functions taking/consuming A's. bothWith happens to be the solution required to model the citizen rule:\n/* * A citizen must provide a non-expired passport along with a matching * id card */ val citizen: Rule[(Date, Passport, IdCard)] = (citizenPassport \u0026amp;\u0026amp; notExpired) // Rule[(Passport, (Date, Date))]  .bothWith(passportMatchesIdCard) { // Rule[(Passport, IdCard)]  case (now, passport, idCard) =\u0026gt; ((passport, (passport.expiration, now)), (passport, idCard)) // ^ ^ ^  // citizenPassport notExpired passportMatchesIdCard  } We first combine citizenPassport and notExpired into a Rule[(Passport, (Date, Date))], then call bothWith to combine the result into a Rule[(Date, Passport, IdCard)] using a function taking the provided input and returning a tuple containing each underlying rule\u0026rsquo;s input. We can proceed the same way to define the foreigner rule (We decomposed the process into more steps for learning purpose):\n/* * A foreigner must provide a non-expired passport and a matching * entry permit */ val foreigner: Rule[(Date, Passport, EntryPermit)] = { val step1: Rule[(Passport, (Date, Date))] = foreignPassport \u0026amp;\u0026amp; notExpired val step2: Rule[(Passport, EntryPermit)] = passportMatchesEntryPermit step1.bothWith(step2) { case (now, passport, permit) =\u0026gt; ((passport, (passport.expiration, now)), (passport, permit)) // ^ ^ ^  // foreignPassport notExpired passportMatchesEntryPermit  } } We now have almost all the pieces to define the general rule of the game. To do so, we have to compose the citizen with the foreigner so that:\n// Pseudo code val visitorRule: Rule[???] = citizen || foreigner We don\u0026rsquo;t have any operator for doing such composition yet, but before coding anything let\u0026rsquo;s ask ourselves what the return type of that operator should be. If we think about it, the resulting type should capture the idea that the rule requires one or another input. For this reason, Either is a natural choice:\ntype Citizen = (Date, Passport, IdCard) type Foreigner = (Date, Passport, EntryPermit) type ||[A, B] = Either[A, B] val visitorRule: Rule[Citizen || Foreigner] = ??? Let\u0026rsquo;s now implement the operator needed to do such composition:\ncase class Rule[A](run: A =\u0026gt; Result) { self =\u0026gt; // ...  def ||[B](that: Rule[B]): Rule[Either[A, B]] = Rule { case Left(a) =\u0026gt; self.run(a) case Right(b) =\u0026gt; that.run(b) } } The implementation is pretty straightforward, but the result is not that great:\ntype Citizen = (Date, Passport, IdCard) type Foreigner = (Date, Passport, EntryPermit) type ||[A, B] = Either[A, B] val visitorRule: Rule[Citizen || Foreigner] = citizen || foreigner /* which is equivalent to val visitorRule: Rule[ (Date, Passport, IdCard) || (Date, Passport, EntryPermit) ] = citizen || foreigner */ Just like earlier we have too many redundancies in the resulting type and some refinement is required. Let\u0026rsquo;s implement a more generic version of ||:\ncase class Rule[A](run: A =\u0026gt; Result) { self =\u0026gt; /* * Combines two rules respectively requiring an `A` and a `B` * into a rule requiring either an `A` or a `B`. */ def eitherWith[B, C]( that: Rule[B] )(f: C =\u0026gt; Either[A, B]): Rule[C] = Rule { c =\u0026gt; f(c) match { case Left(a) =\u0026gt; self.run(a) case Right(b) =\u0026gt; that.run(b) } } } In other words, as long as we know how to convert an input C into an either of A and B, we can combine two rules taking respectively an A and a B. Just like bothWith, eitherWith happens to be a primary operator from which || is derived:\ncase class Rule[-A](run: A =\u0026gt; Result) { self =\u0026gt; /* * Alias for `either` */ def ||[B](that: Rule[B]): Rule[Either[A, B]] = either(that) /* * Alias for `eitherWith` with the identity function provided */ def either[B](that: Rule[B]): Rule[Either[A, B]] = eitherWith(that)(identity) } eitherWith is another typical composition pattern you may come across while writing composable software. It fits well with data-structures being invariant or covariant in A, that is which provide functions returning/producing A's. This new operator happens to be exactly what we need to compose the visitor rule:\n/* * A visitor other than a refugee must either: * - provide a valid passport and an id card (citizen rule) * - or provide a valid passport and an entry permit (foreigner rule) */ val visitor: Rule[(Date, Passport, IdCard || EntryPermit)] = citizen.eitherWith(foreigner) { case (now, passport, Left(idCard)) =\u0026gt; Left((now, passport, idCard)) case (now, passport, Right(permit)) =\u0026gt; Right((now, passport, permit)) } Sum and Product composition You may notice a certain similarity between bothWith and eitherWith. This is not surprising, as they both define two kinds of composition patterns respectively known as product composition and sum composition:\ndef bothWith[B, C] (that: Rule[B])(f: C =\u0026gt; (A, B)): Rule[C] = /* ... */ def eitherWith[B, C](that: Rule[B])(f: C =\u0026gt; A || B): Rule[C] = /* ... */ These two patterns mirror each others in regards to composition, and it\u0026rsquo;s overall a best practice to look for them whenever you write a composable DSL.\nFallback rule In some cases, the game may be aborted under extreme circumstances such as a terrorist attack. Let\u0026rsquo;s see how we could reflect that in our model:\n// Pseudo code val game: Rule[(Passport, IdCard || EntryPermit)] = visitor + terroristAttack First let\u0026rsquo;s think about how terroristAttack should be represented. Overall, this rule does not care about the document provided. So technically it could take any document, and as an output always return Aborted:\nRule(_ =\u0026gt; Aborted) Secondly, combining terroristAttack with another rule should not change the type of the latter. So the combination of terroristAttack with visitorRule should have the same type than visitorRule. This can be implemented in different ways, using contravariance for example:\n// Note the - in front of A case class Rule[-A](run: A =\u0026gt; Result) { /* ... */ } val terroristAttack: Rule[Any] = Rule(_ =\u0026gt; Aborted) Let\u0026rsquo;s now encode the operator combining visitor with terroristAttack:\ncase class Rule[-A](run: A =\u0026gt; Result) { self =\u0026gt; def orElse[A0 \u0026lt;: A](that: Rule[A0]): Rule[A0] = Rule { a =\u0026gt; val r0 = self.run(a) val r1 = that.run(a) ??? } } To finish this implementation, we\u0026rsquo;ll need to provide a way to combine Result so that r0 falls back to r1 whenever it\u0026rsquo;s not Approved:\nsealed trait Result { self =\u0026gt; // ...  def ||(that: Result): Result = self match { case Detained | Denied =\u0026gt; that case _ =\u0026gt; self } } Using this new combinator, we can now finish orElse's implementation:\ncase class Rule[-A](run: A =\u0026gt; Result) { self =\u0026gt; // ...  def orElse[A0 \u0026lt;: A](that: Rule[A0]): Rule[A0] = Rule { a =\u0026gt; val r0 = self.run(a) val r1 = that.run(a) r0 || r1 } } As you can guess, this is another typical composition pattern that can be generalized like following:\ncase class Rule[-A](run: Context[A] =\u0026gt; Result) { self =\u0026gt; // ...  def orElse[A0 \u0026lt;: A](that: Rule[A0]): Rule[A0] = zipWith(that)(_ || _) def zipWith[A0 \u0026lt;: A]( that: Rule[A0] )(f: (Result, Result) =\u0026gt; Result): Rule[A0] = Rule { ctx =\u0026gt; val r0 = self.run(ctx) val r1 = that.run(ctx) f(r0, r1) } } This implementation of zipWith is specific to our domain. Generally, zipWith looks more like the following:\ncase class Data[A](value: A) { self =\u0026gt; // ...  def zip[A, B](that: Data[B]): Data[(A, B)] = zipWith(that)((_, _)) def zipWith[B, C]( that: Data[B] )(f: (A, B) =\u0026gt; C): Data[C] = Data { ctx =\u0026gt; f(self.value, that.value) } } In our example however, having a Rule returning a product of Result (that is a (Result, Result)) is unsound from a domain perspective. zipWith is a covariant analogue of bothWith. It is mostly found in invariant and covariant data-structures and is probably one of the most common composition pattern. With this new tool in our belt, we can finish the description of the game\u0026rsquo;s rules:\nval game: Rule[(Passport, IdCard || EntryPermit)] = visitor.orElse(terroristAttack) Hold on, what about the refugee rule? Thanks to our new combinators, introducing that one is a piece of cake:\ntype Refugee = (GrantOfAsylum, FingerPrints) type Visitor = (Date, Passport, IdCard || EntryPermit) val game: Rule[Visitor || Refugee] = (visitor || refugee).orElse(terroristAttack) Going further Is that it? Well, actually there\u0026rsquo;s more we can talk about regarding this topic. So far we represented every terms of our DSL using a simple function:\nA =\u0026gt; Result In other words, the evaluation of the solution is embedded in the resulting data-structure. This happened to be pretty useful but there are some drawbacks:\n Testability: the solution being a function, there is no way to inspect its content without executing it. If the function has unexpected side-effects, we would lose the ability to reason about it locally. Optimization: rules can currently only be composed using function composition. This prevents us to perform any optimization in the way these functions are called and run. Extendability: if we had to provide another way to evaluate the solution, we would have to change every operator (bothWith, eitherWith, zipWith) and primitive (notExpired, refugee, passportMatchesIdCard, \u0026hellip;) provided by this DSL.  Another way to encode this domain would be to solely rely on pure data-structures. Instead of embedding the evaluation function, we can put that one aside and represent the output of each operator using a date-structure:\nobject DSL { type ||[A, B] = Either[A, B] final case class Always[F[_]](result: Result) extends DSL[Any, F] final case class OrElse[A, F[_]]( left: DSL[A, F], right: DSL[A, F] ) extends SL[A, F] final case class BothWith[A, B, C, F[_]]( left: DSL[A, F], right: DSL[B, F], f: C =\u0026gt; (A, B) ) extends DSL[C, F] final case class EitherWith[A, B, C, F[_]]( left: DSL[A, F], right: DSL[B, F], f: C =\u0026gt; A || B ) extends DSL[C, F] case class Pure[F[_], A](fa: F[A]) extends DSL[A, F] } But what is that F[_]? F[_] is a way to compose this dsl with another one, like Rule for example:\nsealed trait Rule[-A] object Rule { final case object CitizenPassport extends Rule[Passport] final case object ForeignPassport extends Rule[Passport] final case object Refugee extends Rule[(GrantOfAsylum, FingerPrints)] final case object PassportMatchesIdCard extends Rule[(Passport, IdCard)] final case object PassportMatchesEntryPermit extends Rule[(Passport, EntryPermit)] final case object NotExpired extends Rule[(Date, Date)] final case object TerroristAttack extends Rule[Any] } The combination of these two DSLs would look like this:\ntype RuleF[A] = DSL[A, Rule] val notExpired: RuleF[(Date, Date)] = Pure(NotExpired) val citizenPassport: RuleF[Passport] = Pure(CitizenPassport) val foreignPassport: RuleF[Passport] = Pure(ForeignPassport) val terroristAttack: RuleF[Any] = Pure(TerroristAttack) val refugee: RuleF[(GrantOfAsylum, FingerPrints)] = Pure(Refugee) val passportMatchesIdCard: RuleF[(Passport, IdCard)] = Pure(PassportMatchesIdCard) val passportMatchesEntryPermit: RuleF[(Passport, EntryPermit)] = Pure(PassportMatchesEntryPermit) What about the combinators? These actually do not need to change that much:\nsealed trait DSL[-A, F[_]] { self =\u0026gt; def \u0026amp;\u0026amp;[B](that: DSL[B, F]): DSL[(A, B), F] = bothWith(that)(identity) def eitherWith[B, C]( that: DSL[B, F] )(f: C =\u0026gt; Either[A, B]): DSL[C, F] = EitherWith(self, that, f) def ||[B](that: DSL[B, F]): DSL[Either[A, B], F] = eitherWith(that)(identity) def bothWith[B, C](that: DSL[B, F])(f: C =\u0026gt; (A, B)): DSL[C, F] = BothWith(self, that, f) def orElse[A0 \u0026lt;: A](that: DSL[A0, F]): DSL[A0, F] = OrElse(self, that) } and the remaining rules can be left as is, as they are expressed only using existing solutions (refugee, citizenPassport\u0026hellip;) and operators (\u0026amp;\u0026amp;, ||. eitherWith, \u0026hellip;):\nval game: RuleF[Visitor || Refugee] = (visitor || refugee).orElse(terroristAttack) Once we have the right data-structure, we need a function to evaluate it:\ndef run[A, F[_]](rule: DSL[A, Rule])(ctx: A): Result = rule match { case Always(r) =\u0026gt; r case oe: OrElse[A, Rule] =\u0026gt; run(oe.left)(ctx) || run(oe.right)(ctx) case bw: BothWith[a, b, A, Rule] =\u0026gt; val (a, b) = bw.f(ctx) run(bw.left)(a) \u0026amp;\u0026amp; run(bw.right)(b) case ew: EitherWith[a, b, A, Rule] =\u0026gt; ew.f(ctx) match { case Left(a) =\u0026gt; run(ew.left)(a) case Right(b) =\u0026gt; run(ew.right)(b) } case Pure(fa) =\u0026gt; eval(fa)(ctx) } def eval[A](rule: Rule[A])(value: A): Result = rule match { case CitizenPassport =\u0026gt; if (value.foreign) Denied else Approved case ForeignPassport =\u0026gt; if (value.foreign) Approved else Denied case NotExpired =\u0026gt; val (l, r) = value if (l \u0026lt;= r) Approved else Denied case PassportMatchesIdCard =\u0026gt; val (passport, idCard) = value if (passport.uid == idCard.uid) Approved else Detained case PassportMatchesEntryPermit =\u0026gt; val (passport, permit) = value if (passport.uid == permit.uid) Approved else Detained case Refugee =\u0026gt; val (grant, prints) = value if (grant.fingerPrints.data == prints.data) Approved else Detained case TerroristAttack =\u0026gt; Aborted } Note that we use two functions here, one for each DSL. Secondly, these are not stack-safe and would crash if recursive rules are created. We can fix this using techniques such as Trampolining, but this will be the topic of another post.\nTaking some steps back No matter the approach, we ended up using three types of block:\n primitives: which model simple solutions (notExpired, CitizenPassport\u0026hellip;) constructors: which build solutions from existing solutions (citizen, foreigner, \u0026hellip;) operators: which transform/combine solutions into other solutions (eitherWith, bothWith, \u0026hellip;).  As explained by John DeGoes and Ruurtjan Pul in this post, there are some best practices regarding how primitives should be designed:\n  Composable: to build complex solutions using simple components; Orthogonal: such that thereâs no overlap in capabilities between primitives; Minimal: in terms of the number of primitives.   Secondly, in terms of encoding, we first embedded the evaluation function within the resulting data-structure. Later on we decided to pull it apart and use pure data-structures only. The first type of encoding is referred to as an executable encoding. It implies that every constructor and operators of the model is expressed in terms of its execution. It\u0026rsquo;s defined in opposition with the declarative encoding used in the second implementation, where every constructor and operator of the model is expressed as pure data in a recursive tree structure.\nBoth types of encoding have their trade-offs. With an executable encoding, adding new constructors and operators is easy, as they are all defined using the same function, while adding new evaluation functions is harder, as it potentially requires changing every operator and constructors of the DSL. It\u0026rsquo;s the exact opposite with a declarative encoding where adding new evaluation functions is easy (as these are defined separately), but adding new constructors and operators is painful. You may recognize the expression problem here which is the very reason why Object Oriented Programming and Functional Programming exist.\nMoreover, both encodings tend to perform better in specific cases. The declarative encoding will usually be a better fit for use-cases involving optimizations (thanks to inspections capabilities) and/or persistence (thanks to pure data-structures), while the executable encoding is a better choice when it comes to improve legacy code. If you would like to go further, it is highly suggested to read the following post, which inspired this article a lot.\nWrapping Up This post was rather long, so here is a quick recap:\n To improve composition, define primitives, constructors and operators using the best practices described above Provide these with binary operators to compose them forever (bothWith, eitherWith, zipWith, \u0026hellip;) Use the adequate encoding (executable/declarative) depending on your use-case but keep in mind that a declarative encoding suits a greenfield project better.  The code of this post is all available here. Thank you for reading, and thanks to John De Goes for all his time teaching us writing better code.\n","permalink":"https://contramap.dev/posts/2020-09-22-composition/","summary":"An efficient software design is one allowing its components to be separated and recombined without introducing unexpected behaviors. This topic has been tackled over and over in the past and different approaches like the SOLID principles or the GOF patterns eventually came up to address this problem. Despite their value, these tend to confuse many software developers however. Taken separately, they may indeed sound incomplete and often fail to convey what ties them all together.","title":"Composition"},{"content":"In the previous post, we briefly covered how a typeclass can be implemented and ended up asking ourselves how multiple implementations of a typeclass could be done for the same data type while not compromising the implicit mechanism (in other words, type class coherency).\nThis technique has been deeply covered in a Spartan session presented by John De Goes, and this is a small teaser of what one can learn while attending his course:\ntrait Associative[A] { def combine(a0: A, a1: A): A } object Associative { def apply[A: Associative]: Associative[A] = implicitly[Associative[A]] implicit val intAssociative: Associative[Int] = _ + _ /* which is syntactic sugar for: implicit val intAssociative: Associative[Int] = (a, b) =\u0026gt; a + b */ // ... } The Associative typeclass describes how two values of the same type can be combined using an associative combinator. In order for a structure to be associative, the combinator must obey the following law:\na + (b + c) === (a + b) + c This is an aspect of typeclasses we have not mentioned in the previous post. Each typeclass has specific laws that must be satisfied by its implementations (commonly called instances in the functional programming jargon). There is no such thing as a lawless typeclass (otherwise it cannot be referred to as one).Back to our problem, when it comes to Int, there are two possible implementations to satisfy this associative law:\nimplicit val intSumAssociative : Associative[Int] = _ + _ implicit val intProductAssociative: Associative[Int] = _ * _ As we explained it in the previous post, the compiler throws an error whenever it cannot figure out which one of two or more implicits definitions should be selected to satisfy an implicit requirement. Therefore, it may seem at first impossible to create two implicit implementations of a typeclass, in the same implicit scope, for the same data type (eg. Int).\nValue Type One approach to get around this, would consist in creating a value type:\ncase class Mult(value: Int) extends AnyVal object Associative { implicit val sum : Associative[Int] = _ + _ implicit val product: Associative[Mult] = (a0, a1) =\u0026gt; Mult(a0.value * a1.value) } This is not bad, but very inefficient (in terms of memory usage and ergonomics) even using AnyVal. AnyVal would prevent some extra allocations for sure but won\u0026rsquo;t get us too far:\ndef reduce[A: Associative](zero: A, as: List[A]): A = as.fold(zero)(Associative[A].combine) We would lose the benefits of AnyVal as soon as a List[Mult] is passed to reduce as memory allocation is required when a value value class is used as a type argument:\nreduce(Mult(0), List(Mult(1), Mult(2))) // Mult(3) What we really need is a way to create a new type that can be used in place of another, while being considered different during the implicit lookup, so that an Associative[Mult] is different than an Associative[Int].\nNaive approach Haskell provides a feature called newtype which exactly does that. Let\u0026rsquo;s try to implement a similar feature in Scala and take a step-by-step approach:\nsealed trait Newtype[A] { type WrappedType = A def wrap(a: A): WrappedType = a } Newtype[A] defines a type that can be used in place of an A. It provides a wrap function which given an A returns a Newtype[A].WrappedType. If you look closely, you will notice that WrappedType is a type alias for A:\nobject Mult extends Newtype[Int] type Mult = Mult.WrappedType val m1: Mult = Mult.wrap(1) def add1(i: Int): Int = i + 1 add1(m1) // 2 First, an object Mult is defined to represent the newtype. A type alias Mult is then created on Mult.WrappedType which points to A. This works fine, but this does not give us much compared to a simple type alias:\ntype Mult = Int val m1: Mult = 1 def add1(i: Int): Int = i + 1 add1(m1) // 2 And when it comes to implicits, Scala does not make any difference between an Associative[Int] and an Associative[Mult]. The problem here is that the compiler still knows that Mult stands for Int. This connection needs to be broken somehow so they are not considered the same. We could do this using an additional interface:\ntrait Foo { type Bar = Int def bar: Bar = 42 } val foo: Foo = new Foo {} val i : Int = foo.bar // compiles In the above example, Scala knows that Bar is a type alias for Int. Therefore, a Foo#Bar can be used in place of an Int, and these two are considered the same. However, this connection breaks whenever an additional abstraction layer is introduced:\ntrait Foo { type Bar def b(): Bar } class FooImpl extends Foo { type Bar = Int def b(): Bar = 42 } val foo: Foo = new FooImpl val i: foo.Bar = foo.b() // compiles val i: Int = foo.b() // does not compiles /* ^ error: type mismatch; found : foo.Bar required: Int */ As shown by this example, Bar and Int become distinct types even though they are the same. This is because foo is defined as a Foo and not a FooImpl. When referring to Foo, there is no way to prove that Foo#Bar points to Int. So foo.b() could technically return anything.\nThe real newtype Using what we\u0026rsquo;ve just learnt, let\u0026rsquo;s use a similar approach with Newtype[A]:\nsealed trait Newtype[A] { type WrappedType def wrap(a: A): WrappedType } val Mult: Newtype[Int] = new Newtype[Int] { type WrappedType = Int def wrap(a: Int): WrappedType = a } type Mult = Mult.WrappedType val m0: Mult = Mult.wrap(1) // compiles val m1: Int = Mult.wrap(1) // does not compile The connection between Mult and Int is now broken, and they are not considered as the same type by Scala anymore. However, we lost the ability to use a Mult in place of an Int. In some cases that\u0026rsquo;s exactly what we would like to achieve but not always. For this reason, we could make the distinction between Newtype which is unrelated to the initial type (this is how Haskell implements it), and Subtype which \u0026ldquo;extends\u0026rdquo; it:\nsealed trait Newtype[A] { type WrappedType // ... } sealed trait Subtype[A] { type WrappedType \u0026lt;: A // ... } // ... val Mult: Subtype[Int] = new Subtype[Int] { type WrappedType = Int def wrap(a: Int): WrappedType = a } type Mult = Mult.WrappedType val m0: Mult = Mult.wrap(1) // compiles val m1: Int = Mult.wrap(1) // compiles Note: We won\u0026rsquo;t go through the Subtype facilities implementation to avoid going too much through similar code. You may refer to the complete code here.\nSo far, in terms of memory allocation the only cost is the one implied by creating Mult. Wrapping a type to a WrappedType only consists of a function call with no extra allocation. This approach is therefore more contraining than a type alias but at least as efficient memory wise than using a value class.What about implicit resolution now? Can we declare two implementations of the Associative typeclass for, technically speaking, the same data type? To achieve this, we would need a bit more than just wrap:\nsealed trait Newtype[A] { // ...  def unwrap(wt: WrappedType): A } val Mult: Newtype[Int] = new Newtype[Int] { // ...  def unwrap(wt: WrappedType): Int = wt } implicit val sum : Associative[Int] = _ + _ implicit val product: Associative[Mult] = (a0, a1) =\u0026gt; Mult.wrap( Mult.unwrap(a0) * Mult.unwrap(a1) ) Let\u0026rsquo;s see if we can use this with reduce without getting a compilation error:\nreduce(1, List(2, 3)) // 2 + 3 = 5  reduce( Mult.wrap(1), List(Mult.wrap(2), Mult.wrap(3)) ) // 2 * 3 = 6 Great! we\u0026rsquo;ve just managed to create a type that is more constraining that an type alias, and more efficient memory wise than using a value class. Before going forward, let\u0026rsquo;s look at how the code looks like so far:\nsealed trait Newtype[A] { type WrappedType def wrap(a: Int): WrappedType def unwrap(wt: WrappedType): A } val Mult: Newtype[Int] = new Newtype[Int] { type WrappedType = Int def wrap(a: Int): WrappedType = a def unwrap(wt: WrappedType): Int = wt } implicit val sum : Associative[Int] = _ + _ implicit val product: Associative[Mult] = (a0, a1) =\u0026gt; Mult.wrap( Mult.unwrap(a0) * Mult.unwrap(a1) ) reduce(1, List(2, 3)) // 5 reduce(Mult.wrap(1), List(Mult.wrap(2), Mult.wrap(3))) // 6 Ergonomics This is great but there is a lot of boilerplate. Declaring a newtype should be at most two lines long. If we think about it, no matter the newtype, the implementation of Newtype[A] is always the same. We could therefore provide an additional module dedicated for that:\nobject NewtypeModule { def newtype[A]: Newtype[A] = new Newtype[A] { type WrappedType = A def wrap(a: A): WrappedType = a def unwrap(wt: WrappedType): A = wt } } val Mult: Newtype[Int] = NewtypeModule.newtype[Int] We could also improve the wrapping operation by simply renaming the wrap method to apply:\nsealed trait Newtype[A] { def apply(a: A): WrappedType // ... } The API looks already better:\nval Mult: Newtype[Int] = NewtypeModule.newtype[Int] type Mult = Mult.WrappedType val m0: Mult = Mult(1) Pattern Matching There is one last thing we cannot do with a newtype which is pattern matching. Mult is currently a value which prevents writing anything such as:\nMult(42) match { case Mult(meaningOfLife) =\u0026gt; ??? } To achieve this, Mult has to be an object implementing a unapply method:\nobject Mult extends ??? type Mult = Mult.WrappedType However, Mult can\u0026rsquo;t extend Newtype[Int] otherwise Scala will establish a link between Mult.WrappedType and Int bringing us back to square one. Newtype[Int] should therefore be provided as a dependent type:\nobject Mult extends module.Newtype[Int] type Mult = Mult.WrappedType module is a value providing a dependent type Newtype[A] and which could be implemented like this:\ntrait NewtypeModule { sealed trait Newtype[A] { type WrappedType def apply(a: A): WrappedType def unwrap(wt: WrappedType): A } } val module: NewtypeModule = new NewtypeModule {} Mult can now extends module.Newtype[Int] as described earlier:\nobject Mult extends module.Newtype[Int] { type WrappedType = Int def apply(a: Int): WrappedType = a def unwrap(wt: WrappedType): Int = wt } Reducing Boilerplate So far so good, except that we ended up with even more boilerplate :) If we think about it, we don\u0026rsquo;t really need multiple instances of NewtypeModule. We just need one:\nobject NewtypeModule { val instance: NewtypeModule = new NewtypeModule {} } object Mult extends NewtypeModule.instance.Newtype[Int] { // ... } Secondly, we could factor the implementation of a Newtype[A], as it is the same for every newtype:\ntrait NewtypeModule { def newtype[A]: Newtype[A] // ... } object NewtypeModule { val instance: NewtypeModule = new NewtypeModule { def newtype[A]: Newtype[A] = new Newtype[A] { type WrappedType = A def apply(a: A): WrappedType = a def unwrap(wt: WrappedType): A = wt } } } Finally the API could be improved by creating an abstract class Newtype[A] which delegates the work to NewtypeModule.instance:\ntrait NewtypeModuleExports { import NewtypeModule._ abstract class Newtype[A] extends instance.Newtype[A] { val newtype: instance.Newtype[A] = instance.newtype[A] type WrappedType = newtype.WrappedType def apply(a: A): WrappedType = newtype(a) def unwrap(wt: WrappedType): A = newtype.unwrap(wt) } } NewtypeModuleExports could be then mixed in a package object to prevent any additional import from the user:\npackage io.github.francistoth // if the package is called `newtype` package object newtype extends NewtypeModuleExports This makes the declaration of a newtype really easy:\nobject Mult extends Newtype[Int] type Mult = Mult.WrappedType The last piece consists of adding an unapply method to enable pattern matching capabilities for any newtype:\ntrait NewtypeModule { sealed trait Newtype[A] { type WrappedType def apply(a: A): WrappedType def unwrap(wt: WrappedType): A def unapply(wt: WrappedType): Option[A] = Some(unwrap(wt)) } } // ... Mult(42) match { case Mult(i) =\u0026gt; i } // 42 There we go. The code is available here.\nAdditional thoughts In the past, Calvin and myself have been pushing hard to use strong typing everywhere in our code. We used to rely on value types, macros and libraries such as scala-newtype. Knowing the technique we just covered is one more tool under our belt, and is probably the one we\u0026rsquo;ll use in the future, especially since it will be part of the incoming zio-prelude library.\nCredits Thanks to Calvin, Phil, and John for helping me to write this post and for their mentoring.\n","permalink":"https://contramap.dev/posts/2020-04-11-newtypes/","summary":"In the previous post, we briefly covered how a typeclass can be implemented and ended up asking ourselves how multiple implementations of a typeclass could be done for the same data type while not compromising the implicit mechanism (in other words, type class coherency).\nThis technique has been deeply covered in a Spartan session presented by John De Goes, and this is a small teaser of what one can learn while attending his course:","title":"Newtype"},{"content":"Typeclasses are a very common topic when tackling Functional Programming and is what enables abstraction over similar (and possibly unrelated) data-structures.\nTraditional approach In Object-Oriented Programming, this is usually achieved using an interface or an abstract class.\ntrait Json trait JSonSerializable { def toJson: Json } def serialize[A \u0026lt;: JsonSerializable](a: A): Json = a.toJson class Person extends JSonSerializable { override def toJson: Json = ??? } Despite being pretty simple to understand, this approach comes with several issues. First, it implies that A's hierarchy can be modified which is not always possible. Secondly, if we have control over A, we\u0026rsquo;ll have to bloat Person with some JSON specific code.\nOn the road to typeclasses Ideally, we would like to maintain a clean separation between our domain classes and what can be done with them. One approach would consist in creating a type responsible for JSON serialization:\ntrait JSonSerializer[A] { def toJson(a: A): Json } class Person This trait could be then implemented for all the types we need to serialize:\nval personJsonSerializer: JSonSerializer[Person] = ??? def serialize[A](a: A, js: JSonSerializer[A]): Json = js.toJson(a) This is much better as now the different concerns are properly separated. This approach is actually the one used by typeclasses. Scala does not provide typeclasses out of the box, but these can be emulated using implicits:\n// Defined in JSonSerializer.scala trait JSonSerializer[A] { def toJson(a: A): Json } object JSonSerializer { implicit val personJsonSerializer: JSonSerializer[Person] = ??? } // Defined in another file def serialize[A](a: A)(implicit js: JSonSerializer[A]) = js.toJson(a) serialize(new Person) This works without doing any import thanks to how the compiler looks for implicits.\nImplicit lookup As a recap, when it encounters a function call requiring an implicit argument, the compiler will look for an implicit definition (value or method) having the same type than the missing argument. This lookup is performed in three different scopes, in the following order:\n Local definitions: any implicit definition present at the call-site imports: any implicit definition provided by an import companion objects: any implicit definition present in the companion objects of the types implied by the missing argument (in this case Person and JSonSerializer).  The first implicit definition satisfying the requirements will be used. In case of any ambiguity (that is whenever more than one candidate are found in the same scope), the compilation results in an error.\nBEST PRACTICE: Implicit definitions should always be done in the companion objects. This prevents the user from performing any import.Final encoding Back to our problem, let\u0026rsquo;s get rid of some boilerplate using context bounding:\n// this is syntactic sugar for // def serialize[A](a: A)(implicit js: JSonSerializer[A]) def serialize[A: JSonSerializer](a: A) = implicitly[JSonSerializer[A]].toJson(a) To improve this further, we could create a summoner:\nobject JSonSerializer { // summoner  def apply[A: JSonSerializer]: JSonSerializer[A] = implicitly[JSonSerializer[A]] // ... } def serialize[A: JSonSerializer](a: A) = // Under the hood, this actually makes a call to apply[A].  // JSonSerializer.apply[A].toJson(a)  JSonSerializer[A].toJson(a) Finally, we could enrich any type A for which an implicit JSonSerializer is defined with a function toJson:\ntrait JsonSerializerSyntax { implicit class JsonSerializerOps[A: JSonSerializer](a: A) { def toJson: Json = JSonSerializer[A].toJson(a) } } This trait could be then mixed within a package object at the root of the project\u0026rsquo;s hierarchy. This gives access to all the feature provided by the library without knowing anything about its internals:\n// io.github package object francistoth extends JsonSerializerSyntax import io.github.francistoth._ (new Person).toJson One question you might ask is how to define two implementations of the same typeclass for the same data type. We\u0026rsquo;ll actually cover that in the next post so stay tuned. Meanwhile, you can find the code here.\nCredits Thanks to Justin Heyes Jones, Calvin L. Fernandes, and Nader Ghanbari for helping me to write this post.\n","permalink":"https://contramap.dev/posts/2020-04-09-typeclasses/","summary":"Typeclasses are a very common topic when tackling Functional Programming and is what enables abstraction over similar (and possibly unrelated) data-structures.\nTraditional approach In Object-Oriented Programming, this is usually achieved using an interface or an abstract class.\ntrait Json trait JSonSerializable { def toJson: Json } def serialize[A \u0026lt;: JsonSerializable](a: A): Json = a.toJson class Person extends JSonSerializable { override def toJson: Json = ??? } Despite being pretty simple to understand, this approach comes with several issues.","title":"Typeclasses"},{"content":"The Heterogeneous List aka HList is a pretty well-known data structure in the functional / type programming world and is a very interesting topic to cover as it can teach us a lot about Scala\u0026rsquo;s type system in general. John A. De Goes recently used this concept to model an SQL language in a typesafe fashion and presented its work in a Spartan session.\nThe problem tackled by HLists is about storing elements of different types (that is heterogeneous elements) and retaining information about these types at the same time.\nval xs = List(\u0026#34;a string\u0026#34;, true, 42) // xs: List[Any] = List(a string, true, 42) While being able to store heterogeneous elements, a homogeneous List does not keep track of their types. Instead, it falls back on the first common supertype (Any in this case):\nval xs = List( \u0026#34;a string\u0026#34;, // String -\u0026gt; AnyRef -\u0026gt; Any  true, // Boolean -\u0026gt; AnyVal -\u0026gt; Any  42 // Int -\u0026gt; AnyVal -\u0026gt; Any ) // AnyRef and AnyVal have one parent in common which is Any, // therfore `xs` is a `List[Any]` Ideally, we would like to track the type of each element, just like we would do with tuples:\nval xs: (String, (Boolean, (Int, Unit))) = (\u0026#34;a string\u0026#34;, (true, (42, ()) ) ) We can tackle this problem by providing an appropriate data structure:\nsealed trait HList object HList { case object Empty extends HList case class Cons[A, B \u0026lt;: HList](head: A, tail: B) extends HList } Empty represents an HList with no elements while a Cons is a cell containing one element A along with a tail storing the rest of the HList. An HList can be then built like following:\nval xs: HList = Cons(\u0026#34;a string\u0026#34;, Cons(true, Cons(42, Empty) ) ) This approach solves the problem but the syntax remains very verbose. We can improve this by adding an operator designed to prepend an element to an HList:\nobject HList { // ...  implicit class ops[A \u0026lt;: HList](xs: A) { def prepend[B](b: B): Cons[B, A] = Cons(b, xs) } } // ... val xs = Empty .prepend(42) .prepend(true) .prepend(\u0026#34;a string\u0026#34;) With ops, we tell the compiler that any A subtyping an HList provides a prepend operator designed to add a B in front of the list. This is a bit confusing however as one has to build an HList starting from its last element (Empty). Let\u0026rsquo;s leverage infix notation and right associativity to make this more user-friendly:\nimplicit class ops[A \u0026lt;: HList](a: A) { def :*:[B](b: B): Cons[B, A] = Cons(b, a) } //... val xs: Cons[String, Cons[Boolean, Cons[Int, Empty.type]]] = \u0026#34;a string\u0026#34; :*: true :*: 42 :*: Empty As you probably know, infix operators (that is single parameter operators) suffixed with a : are right associative. This allows us to flip the callee and the caller during a function call:\nclass Foo(val j: Int) { def *:(i : Int): Foo = new Foo(i) } val foo: Foo = 43 *: (new Foo(42)) This trick simplifies the composition of an HList at the value-level but the type of xs is still very verbose.\nval xs: Cons[String, Cons[Boolean, Cons[Int, Empty.type]]] = \u0026#34;a string\u0026#34; :*: true :*: 42 :*: Empty So let\u0026rsquo;s try to do the same improvement at the type-level using some type aliases:\nobject HList { // This alias prevents writing Empty.type everywhere we  // need to refer to `Empty` at the type-level  type Empty = Empty.type type :*:[A, B \u0026lt;: HList] = Cons[A, B] // ... } // ... val xs: String :*: Boolean :*: Int :*: Empty = \u0026#34;a string\u0026#34; :*: true :*: 42 :*: Empty Notice that infix operators work at the value-level but also at the type-level. Using this technique, the type of an HList is now very readable. What about extracting elements from an HList now? To achieve this, an Extractor could be used:\nobject :*: { def unapply[A, B \u0026lt;: HList](cons: Cons[A, B]): Option[(A, B)] = Some((cons.head, cons.tail)) } // ... val s :*: b :*: i :*: _ = \u0026#34;a string\u0026#34; :*: true :*: 42 :*: Empty So far, we focused mainly on prepending one element to an HList but what about concatenating two HLists? Before getting deeper, let\u0026rsquo;s look at the code so far:\nsealed trait HList object HList { type Empty = Empty.type type :*:[A, B \u0026lt;: HList] = Cons[A, B] case object Empty extends HList case class Cons[A, B \u0026lt;: HList](head: A, tail: B) extends HList object :*: { def unapply[A, B \u0026lt;: HList](cons: Cons[A, B]): Option[(A, B)] = Some((cons.head, cons.tail)) } implicit class ops[A \u0026lt;: HList](a: A) { def :*:[B](b: B): B :*: A = Cons(b, a) } val xs: String :*: Boolean :*: Int :*: Empty = \u0026#34;a string\u0026#34; :*: true :*: 42 :*: Empty } Concatenating two lists is less trivial but not too hard either. One approach is to think about the type returned by a function designed for this purpose:\nsealed trait HList { def ++[That \u0026lt;: HList](that: That): ??? } No matter the type being returned, we need it to be a subtype of HList. Therefore:\nsealed trait HList { type Append \u0026lt;: HList def ++[That \u0026lt;: HList](that: That): Append } Append has to be a type member because it may change depending on the subtype of the HList. If you look closely however, you will see that this design is flawed. To convince ourselves, let\u0026rsquo;s look at what this would imply for Empty:\nobject HList { // ...  case object Empty extends HList { override type Append = ??? override def ++[That \u0026lt;: HList](that: That): Append = ??? } } What should be the implementation of Append in Empty? To figure this out, let\u0026rsquo;s look at the problem from a value perspective. Appending a list to an empty list results in returning the list itself. Therefore ++ should be defined like follow:\noverride type Append = ??? override def ++[That \u0026lt;: HList](that: That): Append = that But what type should Append refer to? To fix this issue, we need to look at Append as a type-level function. That is a function which given a type returns another one:\noverride type Append[That \u0026lt;: HList] = That override def ++[That \u0026lt;: HList](that: That): Append[That] = that Append[That \u0026lt;: HList] is a type-level function taking and returning a That, while ++ is a value-level function taking a value typed as a That and returning (once expanded) a That. In other words, there is a symmetry between Append[That \u0026lt;: HList] and ++, each living respectfully in the type-level world and the value-level world. We can now fix the definition of Append in HList:\nsealed trait HList { type Append[That \u0026lt;: HList] \u0026lt;: HList def ++[That \u0026lt;: HList](that: That): Append[That] } Once this understood, implementing ++ in Cons is trivial:\ncase class Cons[A, B \u0026lt;: HList](head: A, tail: B) extends HList { self =\u0026gt; override type Append[That \u0026lt;: HList] = Cons[A, tail.Append[That]] override def ++[That \u0026lt;: HList](that: That): self.Append[That] = Cons(head, tail ++ that) // ... } Once again, notice the symmetry between the type level (tail.Append[That]) and the value level (tail ++ that). To give you a full picture, here\u0026rsquo;s the final code:\nsealed trait HList { type Append[B \u0026lt;: HList] \u0026lt;: HList def ++[That \u0026lt;: HList](that: That): Append[That] } object HList { type :*:[A, B \u0026lt;: HList] = Cons[A, B] type Empty = Empty.type case object Empty extends HList { override type Append[B \u0026lt;: HList] = B override def ++[That \u0026lt;: HList](that: That): That = that } case class Cons[A, B \u0026lt;: HList](head: A, tail: B) extends HList { self =\u0026gt; override type Append[C \u0026lt;: HList] = Cons[A, tail.Append[C]] override def ++[That \u0026lt;: HList](that: That): self.Append[That] = Cons(head, tail ++ that) } object :*: { def unapply[A, B \u0026lt;: HList](cons: Cons[A, B]): Option[(A, B)] = Some((cons.head, cons.tail)) } implicit class ops[A \u0026lt;: HList](a: A) { def :*:[B](b: B): B :*: A = Cons(b, a) } } and here\u0026rsquo;s how you can use it:\nimport HList._ val string :*: bool :*: int :*: _: String :*: Boolean :*: Int :*: Empty = \u0026#34;a string\u0026#34; :*: true :*: 42 :*: Empty val x = \u0026#34;a string\u0026#34; :*: Empty val y = 42 :*: Empty val s :*: i :*: _ = x ++ y The biggest takeaways of this exercise are first that we can get the same flexibility at the value and the type level, and secondly that thinking about types as functions can be a breakthrough when you tackle Type programming. However, the possibilities are not endless in Scala 2.x as there are cases when the compiler wonât be able to track types properly (especially when you start introducing GADTs) but are sufficient enough to provide correctness at the type level in most cases. The situation is vastly improved in Dotty.\nI would like to thank John, Calvin and Adam for their mentoring and help to write this post.\n","permalink":"https://contramap.dev/posts/2020-02-23-hlist/","summary":"The Heterogeneous List aka HList is a pretty well-known data structure in the functional / type programming world and is a very interesting topic to cover as it can teach us a lot about Scala\u0026rsquo;s type system in general. John A. De Goes recently used this concept to model an SQL language in a typesafe fashion and presented its work in a Spartan session.\nThe problem tackled by HLists is about storing elements of different types (that is heterogeneous elements) and retaining information about these types at the same time.","title":"HList"},{"content":"Variance is a topic that may be pretty confusing at first and which results from introducing subtyping into a programming language. The whole question asked by Variance is simple though. Given a type A and its subtype B, can one be safely substituted for the other without affecting the program correctness? John De Goes has recently made two Spartan sessions about this topic, and we will cover some of the thoughts he shared during these.\nSubtype 101 When talking about Variance, it\u0026rsquo;s important to understand the meaning of the word subtype. Too often, we think about subtyping in terms of inheritance. In other words, if B inherits from A then B is a subtype of A. Subtyping is actually more about how compatible two types are. As described by the Liskov Substitution Principle, a type B is a subtype of A, if B can be used when A is expected without affecting the program\u0026rsquo;s correctness.\nclass A class B extends A val a: A = new B val b: B = new A ^ error: type mismatch; found : A required: B B can be used wherever an A is expected but not the other way around. This is because B provides as much capabilities/guarantees as A but not vice-versa. We therefore say that B is a subtype of A. The question asked by variance is therefore whether or not this property is held when A and B are used to define more complex types (eg. List[A], A =\u0026gt;Â B, \u0026hellip;).\nVariance 101 There are overall three types of variance:\n invariance : A \u0026gt;: B does not imply that Foo[A] \u0026gt;: Foo[B] covariance : A \u0026gt;: B implies that Foo[A] \u0026gt;: Foo[B] contravariance: A \u0026gt;: B implies that Foo[A] \u0026lt;: Foo[B]  In Scala, we use the + sign to mark a type as covariant, the - to mark it as contravariant and no sign to mark it as invariant. Concretely:\n// A :\u0026gt; B does not imply F[A] :\u0026gt; F[B] nor F[A] \u0026lt;: F[B] class Invariant[T] val ia: Invariant[A] = new Invariant[A] val ib: Invariant[B] = ia // ERROR  // A :\u0026gt; B implies F[A] :\u0026gt; F[B] trait Covariant[+T] val covb: Covariant[B] = new Covariant[B] val covb: Covariant[A] = covb // OK  // A :\u0026gt; B implies F[A] \u0026lt;: F[B] trait Contravariant[-T] val cona: Contravariant[A] = new Contravariant[A] val conb: Contravariant[B] = cona // OK Substitution rule One good way to think about variance is to look at the substitution process this way:\nval fl: Foo[L] = new Foo[R] // the `=` stands for \u0026#34;can be substituted by\u0026#34;  invariance: does not allow any substitution so R must equal L (L =:= R) covariance: allows one only if R is more specialized (+) than L (L :\u0026gt; R) contravariance allows one only if R is less specialized (-) than L (L \u0026lt;: R)  In other words, the general substitution rule is as follow:\n when types are covariant, L has to be a supertype of R when types are contravariant, L has to be a subtype of R.  Variance and functions When it comes to variance, functions are a pretty interesting case. As you may know, functions in Scala are defined using particular traits such as the one below:\ntrait Function1[-T, +R] { def apply(t: T): R } A function is therefore contravariant in its arguments and covariant in its result:\nval f1: Function1[L1, R0] = new Function1[L0, R1] { /* ... */ } If we apply the general substitution rule mentioned earlier, we conclude that L1 \u0026lt;: L0 and R0 \u0026gt;: R1. In other words, the function on the left has to:\n take a more specialized type as an argument (contravariance) and/or return a less specialized type (covariance)  L0 =\u0026gt; R1 is therefore a subtype of L1 =\u0026gt; R0.\nVariance position Once you start introducing variance, you necessarily end up with conflicts and pretty confusing error messages. The main rule here is that once a type has been marked as covariant or contravariant, it cannot be used in a position requiring the opposite variance:\ntrait Foo[+T] { // functions are contravariant in their argument  def foo(t: T): Unit // error: covariant type T occurs in contravariant  // position in type T of value t } trait Bar[-U] { // functions are covariant in their result  def bar(): U // error contravariant type T occurs in covariant  // position in type (t: T)T of method bar } The compiler prevents us from doing this in order to enforce subtyping rules and guarantee correctness at runtime. To convince yourself, let\u0026rsquo;s think about what you would be allowed to do if variance errors would not be caught at compile time:\nclass A class B0 extends A class B1 extends A trait Foo[+T] { // Assume this compiles  def foo(t: T): Unit } val fb0: Foo[B0] = new Foo[B0] { def foo(b0: B0): Unit = ??? } // Because `Foo[_]` is covariant in `T` val fba: Foo[A] = fb0 // This will crash the program at runtime // as `fba` can only accept `B0`s fba.foo(new B1) trait Bar[-U] { // Assume this compiles  def bar(): U } val ba: Bar[A] = new Bar[A] { def bar(): A = new B0 } // Because `Bar[_]` is contravariant in `U` val bb1: Bar[B1] = ba // This will crash the program at runtime // as `bb1` can only produce `B1`s val b1: B1 = ba.bar() In some cases, we may however need to use a type parameter at different positions. This can be done but under some restrictions.\nIn the first case, T is covariant and cannot be used as a function argument. We can however use an appropriate substitute for foo that satifies the requirements for contravariance. Remember that when types are covariant L has to be a supertype of R.\nval fl: Function1[L, Unit] = new Function1[R, Unit] So a valid substitute for foo would be T1 =\u0026gt; Unit with T1 \u0026gt;: T. This gives us:\ntrait Foo[+T] { def foo[T1 \u0026gt;: T](t: T1): Unit } Similarly in the second case, T is contravariant and cannot be used as a function result. In order to satisfy the requirements for covariance, we need to remember that when types are contravariant, L has to be a subtype of R\nval fl: Function1[L, Unit] = new Function1[R, Unit] So a valid substitute for foo would be T0 =\u0026gt; Unit with T0 \u0026lt;: T. This gives us:\ntrait Foo[-T] { def foo[T0 \u0026lt;: T](t: T0): Unit } Variance flipping As if variance was not complicated enough, a type\u0026rsquo;s variance can also flip depending on the context.\ntrait Foo[-A] { def foo(fa: Foo[A]): Unit /* contravariant type A occurs in covariant position in type Foo[A] of value fa */ } Despite fa being a function argument and A marked as contravariant, the compiler complains about A being used in a covariant position. To understand why this is happening, let\u0026rsquo;s look at how A's variance is calculated in foo. A is first defined as contravariant:\ndef foo(fa: Foo[(-A)]): Unit but because it is used to define a function argument, it is also marked contravariant by foo.\ndef foo(fa: Foo[-(-A)]): Unit In other words, A is marked contravariant twice in foo which makes it covariant at that position, hence the compilation error:\ndef foo(fa: Foo[+A]): Unit The takeaway here is that a type parameter variance can flip depending on its position. This is actually described in the specification of the Scala language. So whenever you get into this kind of issue, apply the same reasoning that we have just described.\nRecap Variance is a complicated topic but it does not need to be. Its main purpose is to provide us with typesafe substitution but also with improved type inference:\nclass Animal class Zebra extends Animal // thanks to covariance val animal: Animal = new Zebra class Hotel[-T] def generic = new Hotel[Animal] // thanks to contravariance val ah: Hotel[Zebra] = generic Secondly, one may wonder how to remember what should be covariant or contravariant. A good mnemonic is to remember that whatever is produced by a class should be marked as covariant while anything consumed by a class should be contravariant. In case of conflict, fall back on the substitution rule.\nSpecial thanks To Calvin, John and Adam for their help writing this post.\nReferences  Checking-variance-annotations Liskov Substitution Principle Specification of the Scala language  ","permalink":"https://contramap.dev/posts/2020-02-12-variance/","summary":"Variance is a topic that may be pretty confusing at first and which results from introducing subtyping into a programming language. The whole question asked by Variance is simple though. Given a type A and its subtype B, can one be safely substituted for the other without affecting the program correctness? John De Goes has recently made two Spartan sessions about this topic, and we will cover some of the thoughts he shared during these.","title":"About Variance"},{"content":"In this post, we will demonstrate a technique called type refinement (Aux pattern) that was covered in a Spartan session by John De Goes.\nWe would like to solve the following problem: Given a Member and a Family, we would like to make sure a Selection is valid at compile-time. A Selection is valid only if the Member provided belongs to the Family passed in parameter.\ncase class Member(name: String) sealed trait Family case class Selection(family: Family, member: Member) A first approach consists in providing a type parameter:\ncase class Member[A](name: String) sealed trait Family[A] case class Selection[A](family: Family[A], member: Member[A]) This would work to a certain extent but the compiler could still be cheated by providing a Member having the same type than a Family while not belonging to it:\ntrait SomeType val lennon: Family[SomeType] = new Family[SomeType] {} val mccartney: Family[SomeType] = new Family[SomeType] {} val john = Member[SomeType](\u0026#34;John\u0026#34;) val paul = Member[SomeType](\u0026#34;Paul\u0026#34;) Selection(lennon, john) // compiles Selection(lennon, paul) // compiles This tells us that a Family's type should not be exposed. Let\u0026rsquo;s use a type member to hide this information:\ncase class Member[A](name: String) sealed trait Family { type Tag } object Family { def mk: Family = new Family {} } Tag is a type member and therefore unique to each Family instance. Secondly, as Family is sealed, it cannot be instantiated from outside the file where it is defined, hence the smart constructor Family.mk. This prevents a user from defining a Tag that could be used for more than one Family.\nNotice also that a value for Tag does not need to be provided when instantiating a Family. We are not done however, as the question is now how to ensure the selection is valid:\ncase class Selection[A](family: Family, member: Member[???]) Ideally, we would like to provide the Member type constructor with the Tag of the Family passed in argument:\ncase class Selection[A]( family: Family, member: Member[family.Tag] ) // does not compile This approach, unfortunately, does not work but there is a workaround known as the Aux pattern. One way to think about this pattern is to see Aux as a getter for some type information encapsulated in the Family type.\ncase class Member[A](name: String) sealed trait Family { type Tag } object Family { type Aux[A] = Family { type Tag = A } def mk: Family = new Family {} } case class Selection[A](family: Family.Aux[A], member: Member[A]) This now guarantees that Family#Tag is equal to A:\nval (f1, f2) = (Family.mk, Family.mk) val john = Member[f1.Tag](\u0026#34;John\u0026#34;) val paul = Member[f2.Tag](\u0026#34;Paul\u0026#34;) Selection(f1, john) // compiles Selection(f1, paul) // does not compile The Aux pattern is a great tool whenever you want to add type constraints while not exposing some internal aspects of DSL. In a future post, we will cover a concrete use case relying on it.\nThanks to Calvin and John for their help writing this post.\n","permalink":"https://contramap.dev/posts/2020-01-24-aux/","summary":"In this post, we will demonstrate a technique called type refinement (Aux pattern) that was covered in a Spartan session by John De Goes.\nWe would like to solve the following problem: Given a Member and a Family, we would like to make sure a Selection is valid at compile-time. A Selection is valid only if the Member provided belongs to the Family passed in parameter.\ncase class Member(name: String) sealed trait Family case class Selection(family: Family, member: Member) A first approach consists in providing a type parameter:","title":"Aux pattern"},{"content":"Following the previous post, here is a nice technique to implement typesafe reflection using GADTs.\nAs you may know, Scala provides us with Phantom types. A Phantom type is parameterized type which the only purpose is to provide type-safety and which is erased at runtime:\n/* A is only present as a type parameter but is not used anywhere else in the structure definition */ case class Foo[A](name: String) This can be used to tag a type with some additional metadata used by the compiler to ensure type-safety:\nobject Foo { def int(name: String) : Foo[Int] = Foo[Int](name) def string(name: String): Foo[String] = Foo[String](name) def bool(name: String) : Foo[Boolean] = Foo[Boolean](name) } The problem, however, is that a Phantom type\u0026rsquo;s information gets lost when used in a pattern matching expression:\ndef run[A](foo: Foo[A]): (String, A) = { (foo.name, foo match { // Note that this A here will be lost because of type-erasure  case Foo[A] =\u0026gt; ??? // then what?  }) } We need a way to hold onto the phantom type and not have it erased at runtime. One way to achieve this is to use an additional type responsible for storing this information along with the implicit mechanism:\nsealed trait Type[A] object Type { implicit case object TInt extends Type[Int] implicit case object TString extends Type[String] implicit case object TBoolean extends Type[Boolean] } We can then retrieve this information using an implicit Type:\nimport Type._ def run[A](foo: Foo[A])(implicit t: Type[A]): (String, A) = { (foo.name, t match { case TInt =\u0026gt; 42 case TString =\u0026gt; \u0026#34;is the meaning of life\u0026#34; case Boolean =\u0026gt; true }) } Note how the compiler can trace the information conveyed by the Phantom type A. If the type is a TInt, then the compiler expects A to be an Int. If it is a TString, then a String is expected, and so on. When using this technique, make sure to seal the trait otherwise the pattern matching won\u0026rsquo;t be exhaustive, and the compiler won\u0026rsquo;t be able to provide you any guarantee.\nIn this example, we explicitly passed an implicit argument (no pun intended), but we can do better and rewrite the run function using the implicitly function along with a context-bound:\ndef run[A: Type](foo: Foo[A]): (String, A) = { val t: Type = implicitly[Type[A]] (foo.name, t match { // ...  }) } or even better, tag an existing type with additional information:\ncase class Foo[A: Type](name: String) { val fooType: A = implicitly[Type[A]] } This technique can be really useful whenever you want to ensure type-safety with a Phantom type while holding onto the information it provides.\n","permalink":"https://contramap.dev/posts/2020-01-22-typesafe_reflection/","summary":"Following the previous post, here is a nice technique to implement typesafe reflection using GADTs.\nAs you may know, Scala provides us with Phantom types. A Phantom type is parameterized type which the only purpose is to provide type-safety and which is erased at runtime:\n/* A is only present as a type parameter but is not used anywhere else in the structure definition */ case class Foo[A](name: String) This can be used to tag a type with some additional metadata used by the compiler to ensure type-safety:","title":"Typesafe reflection"},{"content":"I recently attended a training provided by John De Goes about Generalized Algebraic Data Types (GADTs) and wanted to make a quick recap of what those are.\nAn Algebraic Data Type (ADT) is a sum type built from a collection of sum/product types:\nsealed trait Foo object Foo { case class Bar() extends Foo } In order to make this ADT polymorphic, we have to introduce type parameters in some of the terms of the ADT:\nsealed trait Foo[A] object Foo { case class Bar[A](value: A) extends Foo[A] } GADTs are built on top of polymorphic ADTs and can be created either by specializing at least one of the terms:\nsealed trait Foo[A] object Foo { case class Bar[A](value: A) extends Foo[A] case class BarInt(value: Int) extends Foo[Int] } or by introducing a type parameter not present in the main sum type, that is an existential type:\nsealed trait Foo[A] object Foo { case class Bar[A](value: A) extends Foo[A] case class BarInt(value: Int) extends Foo[Int] case class BarMap[A, B](value: Foo[B], f: B =\u0026gt; A) extends Foo[A] } The particularity of BarMap[A, B] is that the moment we upcast a value of that type, we lose information about B:\nval foo: Foo[Int] = BarInt(42) // `B` is not present in `mapFoo`\u0026#39;s definition val mapFoo: Foo[Int] = BarMap(foo, (_: Int) + 1) mapFoo match { //...  // we cannot know what f precisely is  case BarMap(v, f) =\u0026gt; ??? } However, we can use a type case statement and give a name to B to work around this:\nmapFoo match { //...  case map: BarMap[A, b] =\u0026gt; ??? } We now know map is of type BarMap[Int, b] with value: Foo[b] and f: b =\u0026gt; A):\nval foo : Foo[Int] = BarInt(42) val mapFoo: Foo[Int] = BarMap(foo, (_: Int) + 1) def run[A](f: Foo[A]): A = f match { case Bar(value) =\u0026gt; value // `a` is of type `A`  case BarInt(i) =\u0026gt; i // `i` is an `Int`  case map: BarMap[A, b] =\u0026gt; val f: b =\u0026gt; A = map.f val v: Foo[b] = map.value f(run(v)) // returns an `A`  } val fooInt: Foo[Int] = BarInt(42) val result: Int = run(fooInt) So GADTs allow us to carry information about the type used in the definition of an expression, and therefore introduce a weak form on pattern matching on types.\n","permalink":"https://contramap.dev/posts/2019-11-30-gadt/","summary":"I recently attended a training provided by John De Goes about Generalized Algebraic Data Types (GADTs) and wanted to make a quick recap of what those are.\nAn Algebraic Data Type (ADT) is a sum type built from a collection of sum/product types:\nsealed trait Foo object Foo { case class Bar() extends Foo } In order to make this ADT polymorphic, we have to introduce type parameters in some of the terms of the ADT:","title":"GADTS in a nutshell"},{"content":"This blog got created some years ago but has never been really maintained (Mostly because of a lack of time). Nonetheless I recently decided to document what I work and learn about and to use this blog for that.I gave a very cool talk about microservices at the Techno-Drink meetup recently, and really enjoyed my time. Thank you guys for hosting this event and allowing me to talk. Slides are available here.Aside from that, I recently became one of John De Goes patreon, and attended a first training session about GADTs. The Spartan tier is $300/month which may be considered as a significant price at first, but trust me it is worth every penny. It provides you with an access to all the public trainings John gives, along with extra trainings, and monthly 1-to-1 sessions among others. If you want to boost your Functional Programming skills, this may be a good way to do it.\n","permalink":"https://contramap.dev/posts/2019-11-22-blog_revamped/","summary":"This blog got created some years ago but has never been really maintained (Mostly because of a lack of time). Nonetheless I recently decided to document what I work and learn about and to use this blog for that.I gave a very cool talk about microservices at the Techno-Drink meetup recently, and really enjoyed my time. Thank you guys for hosting this event and allowing me to talk. Slides are available here.","title":"Blog revamping"},{"content":"I am an independent Software developer, convinced agilist and trainer with over 15 years experience developing highly scalable web/mobile/backend applications, optimizing work processes and leading dev teams. I am mostly specialized in Scala, Functional Programming, distributed systems, and Software Design. I also speak at various events, love music and outdoor activities.  Scala, ZIO, Cats, Akka, Java, Haskell, Object Oriented / Functional Programming, Reactive Architectures\n People I like to work with:  Adam Peck Calvin L. Fernandes Christopher Hunt John De Goes Nicolas Huray Yunan Zhao  ","permalink":"https://contramap.dev/about/","summary":"I am an independent Software developer, convinced agilist and trainer with over 15 years experience developing highly scalable web/mobile/backend applications, optimizing work processes and leading dev teams. I am mostly specialized in Scala, Functional Programming, distributed systems, and Software Design. I also speak at various events, love music and outdoor activities.  Scala, ZIO, Cats, Akka, Java, Haskell, Object Oriented / Functional Programming, Reactive Architectures\n People I like to work with:  Adam Peck Calvin L.","title":"About"},{"content":" Functional Design - Dawscon 2021 How I learned to stop worrying and love Functional Design - Code Mesh 2020 How I learned to stop worrying and love Functional Design - Explore Functional Programming 2020 Composition (in practice) - Scala Toronto 2020 Composition - Techno Drink 2020 Microservices - Techno Drink 2019 Introduction to Functional Programming - Ottawa Scala meetup 2017 Introduction to Functional Programming - Scalator 2017 Introduction to Functional Programming - Lambda Montreal 2017 Spark 101 - Scala Montreal 2016 Spark 101 - Confoo 2016 Scala 101 - Confoo 2016 Buck - DroidCon Montreal 2015 Modularity in Android - Android Montreal 2013 Android best practices - Android Montreal 2013 Testing Android - Confoo 2012  ","permalink":"https://contramap.dev/talks/","summary":" Functional Design - Dawscon 2021 How I learned to stop worrying and love Functional Design - Code Mesh 2020 How I learned to stop worrying and love Functional Design - Explore Functional Programming 2020 Composition (in practice) - Scala Toronto 2020 Composition - Techno Drink 2020 Microservices - Techno Drink 2019 Introduction to Functional Programming - Ottawa Scala meetup 2017 Introduction to Functional Programming - Scalator 2017 Introduction to Functional Programming - Lambda Montreal 2017 Spark 101 - Scala Montreal 2016 Spark 101 - Confoo 2016 Scala 101 - Confoo 2016 Buck - DroidCon Montreal 2015 Modularity in Android - Android Montreal 2013 Android best practices - Android Montreal 2013 Testing Android - Confoo 2012  ","title":"Talks"}]